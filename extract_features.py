# -*- coding: utf-8 -*-
"""extract_features.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jOuNjUg-JRVsOsqZ6IwGp6vNisKb3hhV
"""
"""
Team:

Naga Sai Nikhil Varma Mantena (101735291)
Chandana Tangellapally(101746055)
"""
"""
REMOVE THE # IN THE BELOW COMMENT TO INSTALL THE REQUIRED LIBRARIES IF BEING RUN ON GOOGLE COLAB
"""
#!pip install pandas scikit-learn tldextract
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
import re
from urllib.parse import urlparse
import tldextract
import numpy as np

# Make sure you have the necessary libraries
# Install them via pip if you haven't already


# Load the dataset
# Replace 'path_to_your_dataset.csv' with the actual path to your CSV file
df = pd.read_csv('malicious_phish.csv')

# 1) TFIDF
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(df['url'])

# 2) Whether a URL has an IP address or not
df['has_ip'] = df['url'].apply(lambda x: bool(re.search(r'\b(?:\d{1,3}\.){3}\d{1,3}\b', x)))

# 3) The number of dots in a URL
df['dot_count'] = df['url'].apply(lambda x: x.count('.'))

# 4) The length of a URL
df['url_length'] = df['url'].apply(len)

# 5) Whether a URL has a redirection script
# This is a simple check and may not catch all types of redirection
df['has_redirection'] = df['url'].apply(lambda x: '//' in x.split('/')[2:])

# 6) Whether a URL contains JavaScript
df['has_javascript'] = df['url'].apply(lambda x: 'javascript:' in urlparse(x).query.lower())

# 7) Presence of HTTPS
df['uses_https'] = df['url'].apply(lambda x: x.startswith('https://'))

# Create a list of suspicious TLDs (this is just an example; the actual list might be longer or based on more recent data)
suspicious_tlds = ['xyz', 'top', 'loan', 'win', 'club']

#8) Add a column to the DataFrame indicating whether the URL's TLD is suspicious
df['suspicious_tld'] = df['url'].apply(lambda x: tldextract.extract(x).suffix in suspicious_tlds)


# Display the first few rows of the DataFrame to verify the added features
print(df.head())

# Note: The TFIDF matrix is not directly displayed here. You might want to use it separately for machine learning models.

from scipy import sparse
import pandas as pd

# Assuming df is your DataFrame after adding all the URL features

# Save the DataFrame with URL features to a CSV file
df.to_csv('lightweight_extracted_features_dataset.csv', index=False)

# Assuming tfidf_matrix is your TFIDF sparse matrix
# Save the TFIDF matrix in sparse format
sparse.save_npz('sparse_tfidf_matrix.npz', tfidf_matrix)